#  Projet Kmeans Digit Recognition

[![Python](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)
[![Machine Learning](https://img.shields.io/badge/ML-Scikit--learn-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## üìã Description

Projet de reconnaissance de chiffres manuscrits (0-9) utilisant plusieurs algorithmes de Machine Learning. Ce projet compare les performances de diff√©rents mod√®les de classification sur le dataset MNIST et g√©n√®re des pr√©dictions pour de nouvelles donn√©es.

## üéØ Objectifs

- D√©velopper et comparer plusieurs mod√®les de classification
- Optimiser les hyperparam√®tres pour obtenir les meilleures performances
- Cr√©er un syst√®me de pr√©diction fiable pour la reconnaissance de chiffres manuscrits
- Visualiser et analyser les r√©sultats

##  Technologies Utilis√©es

### Librairies Python
- **Pandas** & **NumPy** - Manipulation et analyse de donn√©es
- **Matplotlib** & **Seaborn** - Visualisation de donn√©es
- **Scikit-learn** - Mod√®les de Machine Learning
  - Decision Tree Classifier
  - Random Forest Classifier
  - Support Vector Machine (SVM)
- **Pickle** - Sauvegarde des mod√®les entra√Æn√©s

##  Dataset

Le projet utilise le dataset MNIST de chiffres manuscrits :
- **Train Set** : 42,000 images (28√ó28 pixels = 784 features)
- **Test Set** : 28,000 images
- **Classes** : 10 chiffres (0-9)

###  T√©l√©charger les donn√©es

 **Important** : Les fichiers de donn√©es ne sont pas inclus dans le repository GitHub car trop volumineux.

** Google Drive  :**

üì¶ **[T√©l√©charger les datasets et le mod√®le depuis Google Drive](https://drive.google.com/drive/folders/1x0a4Kauqrky1490-vBnWdrZ_IbegDC3g?usp=sharing)**

Le dossier contient :
- `train.csv` (73 MB) - Dataset d'entra√Ænement
- `test.csv` (18 MB) - Dataset de test  
- `best_model.pkl` (172 MB) - Mod√®le entra√Æn√©


### Structure des donn√©es
```
train.csv : [label, pixel0, pixel1, ..., pixel783]
test.csv  : [pixel0, pixel1, ..., pixel783]
```

##  Installation

### Pr√©requis
- Python 3.13+
- pip

### √âtapes d'installation

1. **Cloner le repository**
```bash
git clone https://github.com/Adjakim/Kmeans-Digit-Recognition.git
cd Kmeans-Digit-Recognition
```

2. **T√©l√©charger les datasets** depuis le lien Google Drive ci-dessus et les placer dans le dossier du projet

3. **Cr√©er un environnement virtuel (recommandation)**
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux/Mac
source .venv/bin/activate
```

4. **Installer les d√©pendances**
```bash
pip install -r requirements.txt
```

## üìÅ Structure du Projet

```
Kmeans-Digit-Recognition/
‚îÇ
‚îú‚îÄ‚îÄ mon_exo.ipynb           # Notebook principal avec tout le code
‚îú‚îÄ‚îÄ train.csv               # Dataset d'entra√Ænement (√† t√©l√©charger)
‚îú‚îÄ‚îÄ test.csv                # Dataset de test (√† t√©l√©charger)
‚îú‚îÄ‚îÄ submission.csv          # Fichier de pr√©dictions (g√©n√©r√©)
‚îú‚îÄ‚îÄ best_model.pkl          # Meilleur mod√®le sauvegard√© (√† t√©l√©charger)
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances Python
‚îú‚îÄ‚îÄ .gitignore             # Fichiers √† ignorer
‚îú‚îÄ‚îÄ LICENSE                # Licence MIT
‚îî‚îÄ‚îÄ README.md              # Ce fichier
```

##  M√©thodologie

### 1. Pr√©paration des Donn√©es
- Chargement des datasets train et test
- S√©paration features (X) et labels (y)
- Normalisation des pixels (0-255 ‚Üí 0-1)
- Split train/validation (80/20)

### 2. Mod√®les Test√©s

#### Decision Tree
```python
DecisionTreeClassifier(max_depth=20, random_state=42)
```

#### Random Forest
```python
RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42)
```

#### Support Vector Machine (SVM)
```python
SVC(kernel='rbf', C=1, gamma='scale', random_state=42)
```

### 3. Optimisation
- **GridSearchCV** pour l'optimisation des hyperparam√®tres
- Cross-validation pour √©viter l'overfitting
- Comparaison des m√©triques de performance

### 4. √âvaluation
- Accuracy Score
- Confusion Matrix
- Classification Report (Precision, Recall, F1-Score)
- Visualisation des erreurs de classification

##  R√©sultats

Les performances des mod√®les sont compar√©es selon plusieurs m√©triques :

- **Accuracy** : Taux de classification correcte
- **Precision** : Exactitude des pr√©dictions positives
- **Recall** : Capacit√© √† identifier tous les cas positifs
- **F1-Score** : Moyenne harmonique de Precision et Recall

*Les r√©sultats d√©taill√©s et visualisations sont disponibles dans le notebook.*

##  Utilisation

### Ex√©cuter le Notebook

1. **Lancer Jupyter**
```bash
jupyter notebook mon_exo.ipynb
```

2. **Ex√©cuter les cellules dans l'ordre**
   - Imports et configuration
   - Chargement des donn√©es
   - Exploration et visualisation
   - Entra√Ænement des mod√®les
   - √âvaluation et comparaison
   - Pr√©dictions sur test set
   - G√©n√©ration du fichier submission

### Utiliser le Mod√®le Sauvegard√©

```python
import pickle
import numpy as np

# Charger le mod√®le
with open('best_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Faire une pr√©diction
# image doit √™tre un array de 784 pixels normalis√©s
prediction = model.predict(image.reshape(1, -1))
print(f"Chiffre pr√©dit : {prediction[0]}")
```

##  Visualisations

Le projet inclut plusieurs types de visualisations :

- Distribution des classes dans le dataset
- Exemples d'images pour chaque chiffre
- Matrices de confusion
- Comparaison des performances des mod√®les
- Exemples de pr√©dictions correctes et incorrectes
- Pr√©dictions sur le test set

##  Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Forkez le projet
2. Cr√©ez votre branche (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Pushez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

##  Am√©liorations Futures

- [ ] Impl√©menter des r√©seaux de neurones (CNN)
- [ ] Augmentation de donn√©es (data augmentation)
- [ ] D√©ploiement d'une API REST
- [ ] Interface web pour tester les pr√©dictions
- [ ] Optimisation des performances
- [ ] Tests unitaires

##  Auteur

**Adja Kimy Fatima**  
Passionn√©e de Data Science & Deep Learning

- üåê GitHub : [@Adjakim](https://github.com/Adjakim)
- üìß Email : adjakimfatima@gmail.com
- üíº LinkedIn : [Adja Kimy Fatima](https://linkedin.com/in/adjakim)

**Parcours :**
- üéì Formation en Data, IA et DEV (2025-2026)

##  License

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

##  Remerciements

- Dataset MNIST pour les donn√©es
- Communaut√© Scikit-learn pour les outils de ML
- Kaggle pour l'inspiration et les ressources

---

**Derni√®re mise √† jour** : D√©cembre 2025

‚≠ê Si ce projet vous a √©t√© utile, n'h√©sitez pas √† lui donner une √©toile !